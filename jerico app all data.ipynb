{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\chtn\\gen_ai\\hitesh\\project_xa001\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from urllib.parse import urljoin\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_website(url):\n",
    "    # Get response from the server\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 500:\n",
    "        print(\"Server error\")\n",
    "        return\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Step 1: Find all tab titles\n",
    "    tab_titles = soup.find_all(\"div\", class_=\"elementor-tab-title\")\n",
    "\n",
    "    # Step 2: Find all corresponding tab contents\n",
    "    tab_data = {}\n",
    "\n",
    "    for title_div in tab_titles:\n",
    "        tab_id = title_div.get(\"data-tab\")\n",
    "        tab_title = title_div.get_text(strip=True)\n",
    "\n",
    "        matching_content = soup.find(\"div\", class_=\"elementor-tab-content\", attrs={\"data-tab\": tab_id})\n",
    "        tab_content = matching_content.get_text(separator=\"\\n\", strip=True) if matching_content else \"\"\n",
    "\n",
    "        tab_data[tab_title] = tab_content\n",
    "\n",
    "    # âœ… Create 'data' folder if it doesn't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    # âœ… Save as JSON file\n",
    "    with open(\"data/tab_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tab_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"Data saved to data/tab_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/tab_data.json\n"
     ]
    }
   ],
   "source": [
    "get_data_from_website(\"https://www.dinecollege.edu/academics/academic-policies/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ferpa_data(url, output_filename=\"data//tab_data.json\"):\n",
    "    \"\"\"\n",
    "    Fetches data from a FERPA-related website, processes it, and appends it to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the website to scrape.\n",
    "        output_filename (str, optional): The name of the JSON file to save/append data to.\n",
    "            Defaults to \"data//tab_data.json\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    data = {}\n",
    "    h3_tags = soup.find_all('h3')\n",
    "    for h3_tag in h3_tags:\n",
    "        question = h3_tag.text.strip()\n",
    "        answer_parts = []\n",
    "        sibling = h3_tag.find_next_sibling()\n",
    "        while sibling and sibling.name in ['p', 'div', 'ul', 'ol']:\n",
    "            answer_parts.append(sibling.text.strip())\n",
    "            sibling = sibling.find_next_sibling()\n",
    "        answer = \" \".join(answer_parts).strip()\n",
    "        if question and answer:\n",
    "            data[question] = answer\n",
    "\n",
    "    modified_data = {}\n",
    "    for key, value in data.items():\n",
    "        new_key = key.rstrip(\":\")\n",
    "        modified_value = value.replace(\"Back to Top\", \"\").strip()\n",
    "        if len(modified_value.split()) >= 5:\n",
    "            modified_data[new_key] = modified_value\n",
    "\n",
    "    _append_to_json(modified_data, output_filename)\n",
    "\n",
    "def append_civil_rights_data(url, output_filename=\"data//tab_data.json\"):\n",
    "    \"\"\"\n",
    "    Fetches data from a civil rights laws website, processes it, and appends it to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the website to scrape.\n",
    "        output_filename (str, optional): The name of the JSON file to save/append data to.\n",
    "            Defaults to \"data//tab_data.json\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    final_data = {}\n",
    "\n",
    "    # Extract the main heading and description\n",
    "    main_heading = soup.find('h1', class_='usa-hero__heading')\n",
    "    main_desc = soup.find('div', class_='field--name-body')\n",
    "\n",
    "    if main_heading and main_desc:\n",
    "        title = main_heading.text.strip()\n",
    "        description = main_desc.text.strip()\n",
    "        final_data[title] = description\n",
    "\n",
    "    # Now extract the cards information\n",
    "    cards = soup.find_all('div', class_='card-image-top-txt')\n",
    "\n",
    "    for card in cards:\n",
    "        card_title_tag = card.find('div', class_='field--name-field-ed-card-image-top-title')\n",
    "        card_summary_tag = card.find('div', class_='field--name-field-ed-card-image-top-summary')\n",
    "        card_link_tag = card.find('div', class_='field--name-field-ed-card-image-top-link')\n",
    "\n",
    "        if card_title_tag and card_summary_tag:\n",
    "            card_title = card_title_tag.text.strip()\n",
    "            card_summary = card_summary_tag.text.strip()\n",
    "\n",
    "            # Get the link if available\n",
    "            link = \"\"\n",
    "            if card_link_tag and card_link_tag.find('a'):\n",
    "                href = card_link_tag.find('a')['href']\n",
    "                if href.startswith(\"/\"):\n",
    "                    href = \"https://www.ed.gov\" + href\n",
    "                link = href\n",
    "            final_data[card_title] = f\"{card_summary} link :- {link}\".strip()\n",
    "\n",
    "    _append_to_json(final_data, output_filename)\n",
    "\n",
    "def append_file_complaint_data(url, output_filename=\"data//tab_data.json\"):\n",
    "    \"\"\"\n",
    "    Fetches data from the file a complaint website, processes it, and appends it to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the website to scrape.\n",
    "        output_filename (str, optional): The name of the JSON file to save/append data to.\n",
    "            Defaults to \"data//tab_data.json\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Remove unnecessary tags\n",
    "    for tag in soup([\"script\", \"style\", \"footer\", \"nav\", \"header\", \"aside\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Remove known banners or sections\n",
    "    for div in soup.find_all(['div', 'section'], class_=[\n",
    "        'usa-banner', 'header', 'navigation', 'menu', 'site-header',\n",
    "        'usa-footer', 'main-header', 'branding', 'footer-links'\n",
    "    ]):\n",
    "        div.decompose()\n",
    "\n",
    "    for elem in soup.find_all(id=[\n",
    "        'header', 'footer', 'navbar', 'skip-link', 'back-to-top'\n",
    "    ]):\n",
    "        elem.decompose()\n",
    "\n",
    "    # Get heading\n",
    "    heading = soup.find('h1')\n",
    "    key = heading.get_text(strip=True) if heading else \"No Heading Found\"\n",
    "\n",
    "    # Collect all visible text\n",
    "    body_text = soup.get_text(separator='\\n')\n",
    "    lines = [line.strip() for line in body_text.splitlines() if line.strip()]\n",
    "\n",
    "    # Keywords/phrases to exclude\n",
    "    unwanted_keywords = [\n",
    "        \"Complaint Forms\", \"Electronic Complaint Form Learn how to file\", \"How OCR Evaluates Complaints\",\n",
    "        \"FAQs on the Complaint Process\", \"Customer Service Standards for the Case Resolution Process\",\n",
    "        \"Complainant and Interviewee Rights and Protections\", \"Rights and protections\",\n",
    "        \"Office of Communications and Outreach\", \"Page Last Reviewed\"\n",
    "    ]\n",
    "\n",
    "    # Remove lines matching unwanted sections\n",
    "    filtered_lines = [\n",
    "        line for line in lines\n",
    "        if not any(keyword.lower() in line.lower() for keyword in unwanted_keywords)\n",
    "    ]\n",
    "\n",
    "    # Try to add Electronic Complaint Form and Fillable PDF Complaint Form links\n",
    "    extra_links_text = \"\"\n",
    "    electronic_form = soup.find('a', string=lambda text: text and 'Electronic Complaint Form' in text)\n",
    "    pdf_form = soup.find('a', string=lambda text: text and 'Fillable PDF Complaint Form' in text)\n",
    "\n",
    "    if electronic_form:\n",
    "        href = electronic_form.get('href')\n",
    "        extra_links_text += f\"\\nElectronic Complaint Form: {href}\"\n",
    "    if pdf_form:\n",
    "        href = pdf_form.get('href')\n",
    "        extra_links_text += f\"\\nFillable PDF Complaint Form: {href}\"\n",
    "\n",
    "    # Final value\n",
    "    value = ' '.join(filtered_lines) + extra_links_text\n",
    "\n",
    "    # Result dict\n",
    "    result = {key: value}\n",
    "\n",
    "    _append_to_json(result, output_filename)\n",
    "\n",
    "def _append_to_json(new_data, output_filename):\n",
    "    \"\"\"\n",
    "    Appends a dictionary of data to an existing JSON file or creates a new one.\n",
    "\n",
    "    Args:\n",
    "        new_data (dict): The dictionary data to append.\n",
    "        output_filename (str): The name of the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_filename, 'r+', encoding='utf-8') as f:\n",
    "            try:\n",
    "                existing_data = json.load(f)\n",
    "                existing_data.update(new_data)\n",
    "                f.seek(0)\n",
    "                json.dump(existing_data, f, ensure_ascii=False, indent=4)\n",
    "                f.truncate() # Remove remaining part if new data is shorter\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error decoding existing JSON file. Overwriting with new data.\")\n",
    "                f.seek(0)\n",
    "                json.dump(new_data, f, ensure_ascii=False, indent=4)\n",
    "                f.truncate()\n",
    "    except FileNotFoundError:\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(new_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to data//tab_data.json\n"
     ]
    }
   ],
   "source": [
    "ferpa_url = \"https://studentprivacy.ed.gov/ferpa\"\n",
    "civil_rights_url = \"https://www.ed.gov/laws-and-policy/civil-rights-laws\"\n",
    "file_complaint_url = \"https://www.ed.gov/laws-and-policy/civil-rights-laws/file-complaint\"\n",
    "\n",
    "append_ferpa_data(ferpa_url)\n",
    "append_civil_rights_data(civil_rights_url)\n",
    "append_file_complaint_data(file_complaint_url)\n",
    "\n",
    "print(\"Data appended to data//tab_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_as_text(table):\n",
    "    \"\"\"Convert HTML table to a formatted string.\"\"\"\n",
    "    rows = []\n",
    "    for row in table.find_all('tr'):\n",
    "        cols = [col.get_text(strip=True) for col in row.find_all(['th', 'td'])]\n",
    "        rows.append('\\t'.join(cols))\n",
    "    return '\\n'.join(rows)\n",
    "\n",
    "def append_fafsa_data(url, output_filename=\"data//tab_data.json\"):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # print(\"Soup :-\", soup)\n",
    "    container = soup.find('div', class_='field field--name-body field--type-text-with-summary field--label-hidden field__item')\n",
    "    if not container:\n",
    "        print(\"No content container found.\")\n",
    "        return\n",
    "\n",
    "    result = defaultdict(str)\n",
    "    current_header = None\n",
    "\n",
    "    # Iterate through direct children of the container\n",
    "    for tag in container.find_all(recursive=False):\n",
    "        if tag.name and tag.name.startswith('h'):\n",
    "            current_header = tag.get_text(strip=True)\n",
    "            result[current_header] = ''\n",
    "\n",
    "        elif tag.name == 'p' and current_header:\n",
    "            paragraph_text = tag.get_text(strip=True)\n",
    "            if paragraph_text:\n",
    "                result[current_header] += paragraph_text + '\\n'\n",
    "\n",
    "        elif tag.name == 'table' and current_header:\n",
    "            table_text = extract_table_as_text(tag)\n",
    "            if table_text:\n",
    "                result[current_header] += '\\n' + table_text + '\\n'\n",
    "\n",
    "        elif tag.name == 'div' and current_header:\n",
    "            # Look for any nested tables inside divs (e.g. grid or layout blocks)\n",
    "            nested_table = tag.find('table')\n",
    "            if nested_table:\n",
    "                table_text = extract_table_as_text(nested_table)\n",
    "                if table_text:\n",
    "                    result[current_header] += '\\n' + table_text + '\\n'\n",
    "\n",
    "    # Strip trailing whitespace\n",
    "    result = {k: v.strip() for k, v in result.items() if len(v.strip())>1}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Higher education opens doors to opportunity.': 'The U.S. Department of Education is making transformational changes to the Free Application for Federal Student Aid (FAFSAÂ®) form. The FAFSA form is an application that students and families need to complete to apply for federal student aid, such as federal grants, work-study funds, and loans. Completing and submitting the FAFSA form is free, and it gives students access to the largest source of financial aid to help pay for higher education.\\nThe Better FAFSA is simplified, redesigned, and streamlined. It is faster and easier to fill out, with most students and families completing it in less than 15 minutes. It ensures 665,000 more students will receive Federal Pell Grants to pay for college. Additionally, more than 1.7 million more students will receive the maximum Pell Grant.',\n",
       " 'A Focus on Improving the FAFSAÂ®Experience': 'The Department is pleased to share some of the significant progress that has been made with the help of our partners and improvements we are making for the 2025â€“26 FAFSA cycle.\\xa0The Department is committed to learning from challenges with the launch of the 2024â€“25 FAFSA form, increasing transparency, and making key improvements to the experience for students, families, colleges, and other stakeholders in the coming year.Read more here.',\n",
       " 'Making FAFSA Corrections': 'Some students who already submitted FAFSA forms may need to make corrections. For students who need to make corrections to their FAFSA form, doing so should only take a few minutes. To get started, students and contributors should go to theirStudentAid.gov accountand select the form that notes an \"Action Required\" under \"My Activity.\" Select \"View FAFSA Submission Summary\" to review the information and any actions you need to take to complete the form. Select the \"Make a Correction\" button at the top of the \"FAFSA Form Answers\" tab. Some of the most common corrections include signing the form or providing consent and approval to access and use federal tax data. Remember: successfully completing your FAFSA form is the first step to unlocking affordable and accessible higher education opportunities.\\nWatch these videos to learn more about making corrections to your FAFSA:\\nOther useful resources to help you prepare and submit your FAFSAÂ® Form:',\n",
       " 'High School 2024-25 FAFSA Submission Rate': 'State\\tRate as of 12/20/24\\nPuerto Rico\\t96.30%\\nDistrict Of Columbia\\t76.70%\\nTennessee\\t72.80%\\nLouisiana\\t71.30%\\nMississippi\\t70.30%\\nIllinois\\t69.70%\\nCalifornia\\t69.40%\\nRhode Island\\t68.10%\\nConnecticut\\t66.30%\\nDelaware\\t65.70%\\nThe submission rate is based on the number of high school senior 2024-25 FAFSA submissions divided by the projected total of high school graduates for that state.\\nCheck out high school FAFSA submission rates by statehere(updated 12/18/24)',\n",
       " 'FAFSA Student Support Strategy': \"On May 6, the Department launched the\\u202fFAFSA Student Support Strategy to continue increasing the number of high school students who complete a 2024-25 FAFSA and enroll in college, particularly first-time college students and students of color. This investment builds on the Department's efforts to help students, families, and institutions through the 2024-25 FAFSA application cycle, in addition to theCollege Support Strategy, theFAFSA Fast Breakcampaign, and direct communication efforts with institutions and stakeholders via theFAFSA Fast News blog.\\nAs part of the FAFSA Student Support Strategy, the Department is providing up to\\u202f$50 million\\u202fto help school districts, states, nonprofits, and other public and private organizations with efforts to boost FAFSA completion.\\u202fThese funds will help grow capacity for organizations supporting FAFSA completion efforts, facilitate FAFSA clinics, and provide transportation and communication supports to families as needed. The program will be implemented by ECMC to support organizations with demonstrated experience expanding college access and enrollment. For additional details, read the press releasehere.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# under developement\n",
    "append_fafsa_data(\"https://www.ed.gov/higher-education/paying-college/better-fafsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial correct. will delete that later.\n",
    "\n",
    "# def extract_table_as_text(table):\n",
    "#     \"\"\"Convert HTML table to a formatted string.\"\"\"\n",
    "#     rows = []\n",
    "#     for row in table.find_all('tr'):\n",
    "#         cols = [col.get_text(strip=True) for col in row.find_all(['th', 'td'])]\n",
    "#         rows.append('\\t'.join(cols))\n",
    "#     return '\\n'.join(rows)\n",
    "\n",
    "# def extract_text_with_links(element, base_url):\n",
    "#     \"\"\"Extract text from element and include absolute links.\"\"\"\n",
    "#     # Initialize output\n",
    "#     result = \"\"\n",
    "    \n",
    "#     # Process all children\n",
    "#     for child in element.children:\n",
    "#         if child.name == 'a':\n",
    "#             # Extract link info\n",
    "#             link_text = child.get_text(strip=True)\n",
    "#             link_url = child.get('href', '')\n",
    "            \n",
    "#             # Convert to absolute URL if it's relative\n",
    "#             if link_url and not link_url.startswith(('http://', 'https://')):\n",
    "#                 link_url = urljoin(base_url, link_url)\n",
    "            \n",
    "#             # Add formatted link: text [url]\n",
    "#             if link_url:\n",
    "#                 result += f\"{link_text} [{link_url}]\"\n",
    "#             else:\n",
    "#                 result += link_text\n",
    "#         elif isinstance(child, str):\n",
    "#             # Add plain text\n",
    "#             result += child\n",
    "#         elif child.name:  # Check if it's an element\n",
    "#             # Recursively process other elements\n",
    "#             result += extract_text_with_links(child, base_url)\n",
    "    \n",
    "#     return result.strip()\n",
    "\n",
    "# def extract_list_content(heading_element, base_url):\n",
    "#     \"\"\"Extract list content with absolute links that follows a heading element.\"\"\"\n",
    "#     content = []\n",
    "#     current = heading_element.next_sibling\n",
    "    \n",
    "#     while current:\n",
    "#         if current.name == 'ul':\n",
    "#             for li in current.find_all('li', recursive=True):\n",
    "#                 # Extract text with links for each list item\n",
    "#                 item_content = extract_text_with_links(li, base_url)\n",
    "#                 content.append(item_content)\n",
    "#             break\n",
    "#         elif current.name in ['h2', 'h3']:  # Stop if we hit another heading\n",
    "#             break\n",
    "#         current = current.next_sibling\n",
    "    \n",
    "#     return content\n",
    "\n",
    "# def append_fafsa_data(url, output_filename=\"data/tab_data.json\"):\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         response.raise_for_status()\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Error fetching URL: {e}\")\n",
    "#         return\n",
    "    \n",
    "#     # Extract base URL for converting relative links to absolute\n",
    "#     base_url = url\n",
    "    \n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#     container = soup.find('div', class_='field field--name-body field--type-text-with-summary field--label-hidden field__item')\n",
    "#     if not container:\n",
    "#         print(\"No content container found.\")\n",
    "#         return\n",
    "    \n",
    "#     # Dictionary to store all headers and their associated list items\n",
    "#     result = {}\n",
    "    \n",
    "#     # Find all header tags (h2, h3)\n",
    "#     headers = container.find_all(['h2', 'h3'])\n",
    "    \n",
    "#     for header in headers:\n",
    "#         header_text = header.get_text(strip=True)\n",
    "#         list_items = extract_list_content(header, base_url)\n",
    "        \n",
    "#         # Only add headers that have list items\n",
    "#         if list_items:\n",
    "#             result[header_text] = list_items\n",
    "    \n",
    "#     # Ensure directory exists\n",
    "#     os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    \n",
    "#     # Save to file\n",
    "#     with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(result, f , ensure_ascii=False , indent=2)\n",
    "    \n",
    "#     print(f\"Data saved to {output_filename}\")\n",
    "#     return result\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example usage\n",
    "#     url = \"https://www.ed.gov/higher-education/paying-college/better-fafsa\"\n",
    "#     result = append_fafsa_data(url)\n",
    "#     print(json.dumps(result, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_table_as_text(table):\n",
    "#     rows = []\n",
    "#     for row in table.find_all('tr'):\n",
    "#         cols = [col.get_text(strip=True) for col in row.find_all(['th', 'td'])]\n",
    "#         rows.append('\\t'.join(cols))\n",
    "#     return '\\n'.join(rows)\n",
    "\n",
    "# def extract_text_with_links(element, base_url):\n",
    "#     result = \"\"\n",
    "#     for child in element.children:\n",
    "#         if child.name == 'a':\n",
    "#             link_text = child.get_text(strip=True)\n",
    "#             link_url = child.get('href', '')\n",
    "#             if link_url and not link_url.startswith(('http://', 'https://')):\n",
    "#                 link_url = urljoin(base_url, link_url)\n",
    "#             result += f\"{link_text} [{link_url}]\" if link_url else link_text\n",
    "#         elif isinstance(child, str):\n",
    "#             result += child\n",
    "#         elif child.name:\n",
    "#             result += extract_text_with_links(child, base_url)\n",
    "#     return result.strip()\n",
    "\n",
    "# def extract_list_content(heading_element, base_url):\n",
    "#     content = []\n",
    "#     current = heading_element.next_sibling\n",
    "\n",
    "#     while current:\n",
    "#         if isinstance(current, NavigableString):\n",
    "#             current = current.next_sibling\n",
    "#             continue\n",
    "#         if current.name == 'ul':\n",
    "#             for li in current.find_all('li', recursive=True):\n",
    "#                 item_content = extract_text_with_links(li, base_url)\n",
    "#                 content.append(item_content)\n",
    "#             break\n",
    "#         elif current.name in ['h2', 'h3']:\n",
    "#             break\n",
    "#         current = current.next_sibling\n",
    "\n",
    "#     return content\n",
    "\n",
    "# def extract_h3_with_paragraphs(soup):\n",
    "#     \"\"\"Extract <h3> inside .panel-heading and their <p> inside .panel-body.\"\"\"\n",
    "#     result = {}\n",
    "#     panels = soup.find_all(\"div\", class_=\"panel panel-primary\")\n",
    "#     for panel in panels:\n",
    "#         heading = panel.find(\"div\", class_=\"panel-heading\")\n",
    "#         body = panel.find(\"div\", class_=\"panel-body\")\n",
    "#         if heading and body:\n",
    "#             h3 = heading.find(\"h3\")\n",
    "#             p = body.find(\"p\")\n",
    "#             if h3 and p:\n",
    "#                 heading_text = h3.get_text(strip=True)\n",
    "#                 paragraph_text = p.get_text(strip=True)\n",
    "#                 result[heading_text] = paragraph_text\n",
    "#     return result\n",
    "\n",
    "# def append_fafsa_data(url, output_filename=\"data/tab_data.json\"):\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         response.raise_for_status()\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Error fetching URL: {e}\")\n",
    "#         return\n",
    "\n",
    "#     base_url = url\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     container = soup.find('div', class_='field field--name-body field--type-text-with-summary field--label-hidden field__item')\n",
    "#     if not container:\n",
    "#         print(\"No content container found.\")\n",
    "#         return\n",
    "\n",
    "#     result = {}\n",
    "\n",
    "#     headers = container.find_all(['h2', 'h3'])\n",
    "#     for header in headers:\n",
    "#         header_text = header.get_text(strip=True)\n",
    "#         list_items = extract_list_content(header, base_url)\n",
    "#         if list_items:\n",
    "#             result[header_text] = list_items\n",
    "\n",
    "#     # Extract from panel structure\n",
    "#     panel_data = extract_h3_with_paragraphs(soup)  # <- now uses full soup\n",
    "#     for heading, paragraph in panel_data.items():\n",
    "#         if heading not in result:\n",
    "#             result[heading] = paragraph\n",
    "\n",
    "#     os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "\n",
    "#     with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(result, f, indent=2)\n",
    "\n",
    "#     print(f\"Data saved to {output_filename}\")\n",
    "#     return result\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     url = \"https://www.ed.gov/higher-education/paying-college/better-fafsa\"\n",
    "#     result = append_fafsa_data(url)\n",
    "#     print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to data/tab_data.json\n",
      "{\n",
      "  \"Higher education opens doors to opportunity.\": \"The U.S. Department of Education is making transformational changes to the Free Application for Federal Student Aid (FAFSA\\u00ae) form. The FAFSA form is an application that students and families need to complete to apply for federal student aid, such as federal grants, work-study funds, and loans. Completing and submitting the FAFSA form is free, and it gives students access to the largest source of financial aid to help pay for higher education.\\nThe Better FAFSA is simplified, redesigned, and streamlined. It is faster and easier to fill out, with most students and families completing it in less than 15 minutes. It ensures 665,000 more students will receive Federal Pell Grants to pay for college. Additionally, more than 1.7 million more students will receive the maximum Pell Grant.\",\n",
      "  \"A Focus on Improving the FAFSA\\u00aeExperience\": \"The Department is pleased to share some of the significant progress that has been made with the help of our partners and improvements we are making for the 2025\\u201326 FAFSA cycle.\\u00a0The Department is committed to learning from challenges with the launch of the 2024\\u201325 FAFSA form, increasing transparency, and making key improvements to the experience for students, families, colleges, and other stakeholders in the coming year.Read more here.\",\n",
      "  \"Making FAFSA Corrections\": \"Some students who already submitted FAFSA forms may need to make corrections. For students who need to make corrections to their FAFSA form, doing so should only take a few minutes. To get started, students and contributors should go to theirStudentAid.gov accountand select the form that notes an \\\"Action Required\\\" under \\\"My Activity.\\\" Select \\\"View FAFSA Submission Summary\\\" to review the information and any actions you need to take to complete the form. Select the \\\"Make a Correction\\\" button at the top of the \\\"FAFSA Form Answers\\\" tab. Some of the most common corrections include signing the form or providing consent and approval to access and use federal tax data. Remember: successfully completing your FAFSA form is the first step to unlocking affordable and accessible higher education opportunities.\\nWatch these videos to learn more about making corrections to your FAFSA:\\nOther useful resources to help you prepare and submit your FAFSA\\u00ae Form:\\nBetter FAFSA Corrections and Completion Guidance: Students [https://www.youtube.com/watch?v=0aO9OklHbqw]\\nBetter FAFSA Corrections and Completion Guidance: Parents [https://www.youtube.com/watch?v=UHCtT4mqEjQ]\\nOrientaci\\u00f3n para hacer correcciones y completar la Better FAFSA: Padres [https://www.youtube.com/watch?v=pf3WcNN91kM]\\nBetter FAFSA Corrections and Completion Guidance: Adding Schools [https://www.youtube.com/watch?v=r0bfBp8oF3A]\\nHow to make corrections and add colleges and universities to your FAFSA [https://www.youtube.com/watch?v=nZYVgdZjG58&list=PL1tCTXATxf-qJha84KeHTZ2-8d7hTf2Up]\\nHow to make corrections to the new FAFSA form \\u2014 Adding signature and contributor information [https://www.youtube.com/watch?v=-BlDZfOFyjM&list=PL1tCTXATxf-qJha84KeHTZ2-8d7hTf2Up]\\nHow to correct and submit the signature in the new FAFSA form \\u2014 For students and their contributors [https://www.youtube.com/watch?v=Pb1DY59uqds&list=PL1tCTXATxf-qJha84KeHTZ2-8d7hTf2Up]\\nOrientaci\\u00f3n para hacer correcciones y completar la Better FAFSA: Padres [https://www.youtube.com/watch?v=pf3WcNN91kM](in Spanish)\\nC\\u00f3mo hacer correcciones y a\\u00f1adir universidades a su FAFSA [https://www.youtube.com/watch?v=2sgmE9zcEig] (in Spanish)\\nC\\u00f3mo hacer correcciones al nuevo formularlo FAFSA \\u2014 a\\u00f1adir la firma e informaci\\u00f3n del contribuyente [https://www.youtube.com/watch?v=InqY7jJPqTk] (in Spanish)\\nC\\u00f3mo corregir y enviar la firma en el nuevo formulario FAFSA \\u2014 para estudiantes y sus contribuyentes [https://www.youtube.com/watch?v=3dBNmV5XSyc] (in Spanish)\",\n",
      "  \"High School 2024-25 FAFSA Submission Rate\": \"State\\tRate as of 12/20/24\\nPuerto Rico\\t96.30%\\nDistrict Of Columbia\\t76.70%\\nTennessee\\t72.80%\\nLouisiana\\t71.30%\\nMississippi\\t70.30%\\nIllinois\\t69.70%\\nCalifornia\\t69.40%\\nRhode Island\\t68.10%\\nConnecticut\\t66.30%\\nDelaware\\t65.70%\\nThe submission rate is based on the number of high school senior 2024-25 FAFSA submissions divided by the projected total of high school graduates for that state.\\nCheck out high school FAFSA submission rates by statehere(updated 12/18/24)\",\n",
      "  \"FAFSA Student Support Strategy\": \"On May 6, the Department launched the\\u202fFAFSA Student Support Strategy to continue increasing the number of high school students who complete a 2024-25 FAFSA and enroll in college, particularly first-time college students and students of color. This investment builds on the Department's efforts to help students, families, and institutions through the 2024-25 FAFSA application cycle, in addition to theCollege Support Strategy, theFAFSA Fast Breakcampaign, and direct communication efforts with institutions and stakeholders via theFAFSA Fast News blog.\\nAs part of the FAFSA Student Support Strategy, the Department is providing up to\\u202f$50 million\\u202fto help school districts, states, nonprofits, and other public and private organizations with efforts to boost FAFSA completion.\\u202fThese funds will help grow capacity for organizations supporting FAFSA completion efforts, facilitate FAFSA clinics, and provide transportation and communication supports to families as needed. The program will be implemented by ECMC to support organizations with demonstrated experience expanding college access and enrollment. For additional details, read the press releasehere.\",\n",
      "  \"Better FAFSA Toolkits\": \"FAFSA Guide for Parents and Contributors - Partner Guidance [https://www.ed.gov/sites/ed/files/finaid/info/apply/fafsa-guide-parents-contributors.pdf]\\nGu\\u00eda para Padres y Contribuyentes del FAFSA 2024-25 (in Spanish) [https://www.ed.gov/sites/ed/files/finaid/info/apply/guia-padres-contribuyentes-fafsa.pdf]\\nGu\\u00eda para Padres y Contribuyentes del FAFSA 2024-25 - Gu\\u00eda para Socios (in Spanish) [https://www.ed.gov/sites/ed/files/finaid/info/apply/guia-padres-contribuyentes-fafsa-socios.pdf]\",\n",
      "  \"For students and families\": \"See and share this toolkit [https://www.ed.gov/sites/ed/files/finaid/info/apply/fafsa-toolkit-students-families.pdf] for students and families\\nLearn about [http://studentaid.gov/fafsasupport] the better FAFSA form, and check out this slide deck [https://www.ed.gov/sites/ed/files/finaid/info/apply/better-fafsa-slide-deck.pdf]\\nRead these FAFSA Pro Tips [https://studentaid.gov/announcements-events/fafsa-support/pro-tips] to help you successfully complete the FAFSA form\\nCheck out this video [https://www.youtube.com/watch?v=UupEQdS2VMY] on applying for financial aid with the FAFSA form\\nWatch and share these videos [https://www.youtube.com/watch?v=0D8ytYCTeSY&list=PL1tCTXATxf-qJha84KeHTZ2-8d7hTf2Up&index=5] from students, a parent, an organizational leader, and Department leaders on the Better FAFSA\\nUse the Federal Student Aid Estimator [https://studentaid.gov/aid-estimator/] to receive an estimate of how much federal student aid the student may be eligible to receive\\nUse the Sacha chatbot [https://d1qaw0xov0bofv.cloudfront.net] to get answers to your FAFSA questions\",\n",
      "  \"For high school educators and college access counselors\": \"See and share this toolkit [https://www.ed.gov/sites/ed/files/finaid/info/apply/fafsa-toolkit-educators-counselors.pdf] for high school educators and college access counselors\\nCheck out this roadmap [https://fsapartners.ed.gov/knowledge-center/topics/fafsa-simplification-information/2024-25-fafsa-roadmap#CounselorsAdvocates] for counselors and advocates\\nUse the Financial Aid Toolkit [https://financialaidtoolkit.ed.gov/tk/] for counselors\\nRead 5 Things College Access Professionals Should Know [https://financialaidtoolkit.ed.gov/tk/announcement-detail.jsp?id=5-things-college-access-professionals-should-know]\\nCheck out this slide deck [https://www.ed.gov/sites/ed/files/finaid/info/apply/better-fafsa-slide-deck.pdf]\\nBookmark this page [https://fsapartners.ed.gov/knowledge-center/topics/fafsa-simplification-information/2024-25-fafsa-updates] for regular status updates and resources related to the better FAFSA form\\nWatch and share these videos [https://www.youtube.com/watch?v=0D8ytYCTeSY&list=PL1tCTXATxf-qJha84KeHTZ2-8d7hTf2Up&index=5] from students, a parent, an organizational leader, and Department leaders on the Better FAFSA.\\nSign up [https://fsapartners.ed.gov/subscriptions/] to receive updates on webinars and other information\",\n",
      "  \"For college officials\": \"See and share this toolkit [https://www.ed.gov/sites/ed/files/finaid/info/apply/fafsa-toollkit-colleges-universities.pdf] for college officials\\nCheck out this slide deck [https://www.ed.gov/sites/ed/files/finaid/info/apply/better-fafsa-slide-deck.pdf]\\nCheck out this roadmap [https://fsapartners.ed.gov/knowledge-center/topics/fafsa-simplification-information/2024-25-fafsa-roadmap#InstitutionsStatePartners] for institutions and state partners\\nSee the FSA Knowledge Center [https://fsapartners.ed.gov/knowledge-center/topics/fafsa-simplification-information], a repository for all information, guidance, and training related to better FAFSA\\nWatch and share these videos [https://www.youtube.com/watch?v=0D8ytYCTeSY&list=PL1tCTXATxf-qJha84KeHTZ2-8d7hTf2Up&index=5] from students, a parent, an organizational leader, and Department leaders on the Better FAFSA.\\nBookmark this page [https://fsapartners.ed.gov/knowledge-center/topics/fafsa-simplification-information/2024-25-fafsa-updates] for regular status updates and resources related to the better FAFSA form\\nSign up [https://fsapartners.ed.gov/subscriptions/] to receive updates on webinars and other information\",\n",
      "  \"Resources For Media Outlets\": \"2025-2026 FAFSA Press Kit [https://www.ed.gov/media/document/2025-2026-fafsa-press-kit-108558.pdf]\",\n",
      "  \"Significantly Reducing Verification Requirements\": \"Thanks to the overhauled FAFSA form, the majority of income data now comes directly from the IRS, which will not need to be verified. This year's reduction in verifications will reduce the burden for colleges and students while continuing to protect against fraud.\",\n",
      "  \"Providing Additional Flexibility on Recertification\": \"The Department will, through Sept. 2024, waive the requirement for institutions to recertify eligibility for federal student aid programs no later than 90 days before their Program Participation Requirement expires. This flexibility will give time back to institutions at this critical moment.\",\n",
      "  \"Making Connections to Data\": \"The Department is posting new data and resources to help schools drive FAFSA completion. For example, the Department released data by high school on their students' 2024 \\u2014 2025 FAFSA submissions, two months ahead of schedule.\",\n",
      "  \"Suspending New Routine Program Reviews\": \"The Department suspended new reviews through September 2024, except for the most serious issues, helping colleges focus on getting aid award offers to students.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def extract_table_as_text(table):\n",
    "    rows = []\n",
    "    for row in table.find_all('tr'):\n",
    "        cols = [col.get_text(strip=True) for col in row.find_all(['th', 'td'])]\n",
    "        rows.append('\\t'.join(cols))\n",
    "    return '\\n'.join(rows)\n",
    "\n",
    "def extract_text_with_links(element, base_url):\n",
    "    result = \"\"\n",
    "    for child in element.children:\n",
    "        if child.name == 'a':\n",
    "            link_text = child.get_text(strip=True)\n",
    "            link_url = child.get('href', '')\n",
    "            if link_url and not link_url.startswith(('http://', 'https://')):\n",
    "                link_url = urljoin(base_url, link_url)\n",
    "            result += f\"{link_text} [{link_url}]\" if link_url else link_text\n",
    "        elif isinstance(child, str):\n",
    "            result += child\n",
    "        elif child.name:\n",
    "            result += extract_text_with_links(child, base_url)\n",
    "    return result.strip()\n",
    "\n",
    "def extract_list_content(heading_element, base_url):\n",
    "    content = []\n",
    "    current = heading_element.next_sibling\n",
    "\n",
    "    while current:\n",
    "        if isinstance(current, NavigableString):\n",
    "            current = current.next_sibling\n",
    "            continue\n",
    "        if current.name == 'ul':\n",
    "            for li in current.find_all('li', recursive=True):\n",
    "                item_content = extract_text_with_links(li, base_url)\n",
    "                content.append(item_content)\n",
    "            break\n",
    "        elif current.name in ['h2', 'h3']:\n",
    "            break\n",
    "        current = current.next_sibling\n",
    "\n",
    "    return content\n",
    "\n",
    "def extract_h3_with_paragraphs(soup):\n",
    "    result = {}\n",
    "    panels = soup.find_all(\"div\", class_=\"panel panel-primary\")\n",
    "    for panel in panels:\n",
    "        heading = panel.find(\"div\", class_=\"panel-heading\")\n",
    "        body = panel.find(\"div\", class_=\"panel-body\")\n",
    "        if heading and body:\n",
    "            h3 = heading.find(\"h3\")\n",
    "            p = body.find(\"p\")\n",
    "            if h3 and p:\n",
    "                heading_text = h3.get_text(strip=True)\n",
    "                paragraph_text = p.get_text(strip=True)\n",
    "                result[heading_text] = paragraph_text\n",
    "    return result\n",
    "\n",
    "def append_fafsa_data(url, output_filename=\"data/tab_data.json\"):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return\n",
    "\n",
    "    base_url = url\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    container = soup.find('div', class_='field field--name-body field--type-text-with-summary field--label-hidden field__item')\n",
    "    if not container:\n",
    "        print(\"No content container found.\")\n",
    "        return\n",
    "\n",
    "    result = defaultdict(str)\n",
    "    current_header = None\n",
    "\n",
    "    for tag in container.find_all(recursive=False):\n",
    "        if tag.name and tag.name.startswith('h'):\n",
    "            current_header = tag.get_text(strip=True)\n",
    "            result[current_header] = ''\n",
    "\n",
    "        elif tag.name == 'p' and current_header:\n",
    "            paragraph_text = tag.get_text(strip=True)\n",
    "            if paragraph_text:\n",
    "                result[current_header] += paragraph_text + '\\n'\n",
    "\n",
    "        elif tag.name == 'table' and current_header:\n",
    "            table_text = extract_table_as_text(tag)\n",
    "            if table_text:\n",
    "                result[current_header] += '\\n' + table_text + '\\n'\n",
    "\n",
    "        elif tag.name == 'div' and current_header:\n",
    "            nested_table = tag.find('table')\n",
    "            if nested_table:\n",
    "                table_text = extract_table_as_text(nested_table)\n",
    "                if table_text:\n",
    "                    result[current_header] += '\\n' + table_text + '\\n'\n",
    "\n",
    "    result = {k: v.strip() for k, v in result.items() if len(v.strip()) > 1}\n",
    "\n",
    "    headers = container.find_all(['h2', 'h3'])\n",
    "    for header in headers:\n",
    "        header_text = header.get_text(strip=True)\n",
    "        list_items = extract_list_content(header, base_url)\n",
    "        if list_items:\n",
    "            if header_text in result:\n",
    "                result[header_text] += '\\n' + '\\n'.join(list_items)\n",
    "            else:\n",
    "                result[header_text] = '\\n'.join(list_items)\n",
    "\n",
    "    panel_data = extract_h3_with_paragraphs(soup)\n",
    "    for heading, paragraph in panel_data.items():\n",
    "        if heading in result:\n",
    "            result[heading] += '\\n' + paragraph\n",
    "        else:\n",
    "            result[heading] = paragraph\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "    _append_to_json(result, output_filename)\n",
    "    print(f\"Data appended to {output_filename}\")\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.ed.gov/higher-education/paying-college/better-fafsa\"\n",
    "    result = append_fafsa_data(url)\n",
    "    print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS index and metadata saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data\n",
    "with open('data/tab_data.json', 'r', encoding='utf-8') as f:\n",
    "    tab_data = json.load(f)\n",
    "\n",
    "# Combine tab title and content into a document\n",
    "documents = [f\"{key}: {value}\" for key, value in tab_data.items()]\n",
    "metadata = list(tab_data.keys())\n",
    "\n",
    "# Load a pre-trained embedding model from Hugging Face\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(documents, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# Create FAISS index\n",
    "embedding_dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # Using L2 similarity\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the index\n",
    "faiss.write_index(index, 'data/faiss_index.idx')\n",
    "\n",
    "# Save the metadata for reverse lookup\n",
    "with open('data/faiss_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… FAISS index and metadata saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Top 2 Results for: 'Want to know about the academic appeals.'\n",
      "\n",
      "1. Title: Grades\n",
      "   Score: 0.9125\n",
      "   Content:\n",
      "General Grade Appeal\n",
      "Grades are determined solely by the individual faculty who taught the course for the session(s) or the semester(s). A student who wishes to contest a grade must first attempt to resolve the matter with the course faculty.\n",
      "If the matter cannot be resolved with the instructor, the...\n",
      "\n",
      "2. Title: Academics\n",
      "   Score: 1.0904\n",
      "   Content:\n",
      "Academic Appeals\n",
      "Students placed on academic probation or suspension may appeal to the Academic Standards Committee by filing an appeal form with the Office of the Registrar. The student has the right to appeal any action affecting their academic status by obtaining the appropriate form from the Off...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the saved FAISS index and metadata\n",
    "index = faiss.read_index('data/faiss_index.idx')\n",
    "with open('data/faiss_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Also load the tab_data to fetch full content for results\n",
    "with open('data/tab_data.json', 'r', encoding='utf-8') as f:\n",
    "    tab_data = json.load(f)\n",
    "\n",
    "def search_query(user_query, top_k=2):\n",
    "    # Convert query to embedding\n",
    "    query_vector = model.encode([user_query], convert_to_numpy=True)\n",
    "\n",
    "    # Perform similarity search\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "\n",
    "    # Print top-k matches\n",
    "    print(f\"\\nðŸ” Top {top_k} Results for: '{user_query}'\\n\")\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        title = metadata[idx]\n",
    "        content = tab_data[title]\n",
    "        score = distances[0][i]\n",
    "        print(f\"{i+1}. Title: {title}\")\n",
    "        print(f\"   Score: {score:.4f}\")\n",
    "        print(f\"   Content:\\n{content[:300]}{'...' if len(content) > 300 else ''}\\n\")\n",
    "\n",
    "# Example\n",
    "search_query(\"Want to know about the academic appeals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "        model=\"Llama3-8b-8192\",\n",
    "        temperature=0,\n",
    "        max_tokens=4192,\n",
    "        timeout=30,\n",
    "        max_retries=2,\n",
    "    )\n",
    "\n",
    "def generate_answer(user_query, retrieved_titles, tab_data):\n",
    "    # Combine relevant tab content\n",
    "    retrieved_docs = \"\\n\\n\".join([f\"{title}: {tab_data[title]}\" for title in retrieved_titles if title in tab_data])\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = f\"\"\"\n",
    "You are an expert assistant helping users understand resources related to FAFSA. \n",
    "Answer the user's question **only** based on the information provided below. \n",
    "Do **not** use any external knowledge or make assumptions beyond the provided documents.\n",
    "\n",
    "When answering:\n",
    "- Use a friendly, guiding tone.\n",
    "- Structure the answer in a **clear, easy-to-follow manner**.\n",
    "- Use **storytelling** where appropriate to guide the user step-by-step.\n",
    "- Highlight important tools or resources using bullet points or bold text.\n",
    "- Group information by relevant audience (e.g., students, educators, officials) if applicable.\n",
    "\n",
    "If the answer is **not present** in the information, reply with: \n",
    "\"I'm sorry, but that question is outside the scope of the provided information.\"\n",
    "\n",
    "Information:\n",
    "{retrieved_docs}\n",
    "\n",
    "Question: {user_query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # Generate response using ChatGroq (LLaMA3)\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Answer:\n",
      "I'd be happy to help you understand the resources available for students and families, high school educators and college access counselors, and college officials.\n",
      "\n",
      "**For Students and Families:**\n",
      "\n",
      "* The **FAFSA Toolkit for Students and Families** is a great resource to get started with the FAFSA process. You can find it at [https://www.ed.gov/sites/ed/files/finaid/info/apply/fafsa-toolkit-students-families.pdf].\n",
      "* Learn about the **Better FAFSA Form** and check out the slide deck at [https://www.ed.gov/sites/ed/files/finaid/info/apply/better-fafsa-slide-deck.pdf].\n",
      "* Read the **FAFSA Pro Tips** at [https://studentaid.gov/announcements-events/fafsa-support/pro-tips] to help you successfully complete the FAFSA form.\n",
      "* Watch the video on **Applying for Financial Aid with the FAFSA Form** at [https://www.youtube.com/watch?v=UupEQdS2VMY].\n",
      "* Use the **Federal Student Aid Estimator** at [https://studentaid.gov/aid-estimator/] to receive an estimate of how much federal student aid you may be eligible to receive.\n",
      "* Chat with the **Sacha chatbot** at [https://d1qaw0xov0bofv.cloudfront.net] to get answers to your FAFSA questions.\n",
      "\n",
      "**For High School Educators and College Access Counselors:**\n",
      "\n",
      "* Check out the **FAFSA Toolkit for Educators and Counselors** at [https://www.ed.gov/sites/ed/files/finaid/info/apply/fafsa-toolkit-educators-counselors.pdf].\n",
      "* Use the **Financial Aid Toolkit** at [https://financialaidtoolkit.ed.gov/tk/].\n",
      "* Read the article **5 Things College Access Professionals Should Know** at [https://financialaidtoolkit.ed.gov/tk/announcement-detail.jsp?id=5-things-college-access-professionals-should-know].\n",
      "* Watch the videos on the **Better FAFSA** at [https://www.youtube.com/watch?v=0D8ytYCTeSY&list=PL1tCTXATxf-qJha84KeHTZ2-8d7hTf2Up&index=5].\n",
      "* Bookmark the page [https://fsapartners.ed.gov/knowledge-center/topics/fafsa-simplification-information/2024-25-fafsa-updates] for regular status updates and resources related to the better FAFSA form.\n",
      "* Sign up for updates on webinars and other information at [https://fsapartners.ed.gov/subscriptions/].\n",
      "\n",
      "**For College Officials:**\n",
      "\n",
      "* Check out the **FAFSA Toolkit for Colleges and Universities** at [https://www.ed.gov/sites/ed/files/finaid/info/apply/fafsa-toollkit-colleges-universities.pdf].\n",
      "* Use the **FSA Knowledge Center** at [https://fsapartners.ed.gov/knowledge-center/topics/fafsa-simplification-information] for all information, guidance, and training related to the better FAFSA.\n",
      "* Watch the videos on the **Better FAFSA** at [https://www.youtube.com/watch?v=0D8ytYCTeSY&list=PL1tCTXATxf-qJha84KeHTZ2-8d7hTf2Up&index=5].\n",
      "* Bookmark the page [https://fsapartners.ed.gov/knowledge-center/topics/fafsa-simplification-information/2024-25-fafsa-updates] for regular status updates and resources related to the better FAFSA form.\n",
      "* Sign up for updates on webinars and other information at [https://fsapartners.ed.gov/subscriptions/].\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "def search_and_generate(user_query, top_k=3):\n",
    "    query_vector = model.encode([user_query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "\n",
    "    retrieved_titles = [metadata[idx] for idx in indices[0]]\n",
    "\n",
    "    # Generate the answer using LLaMA (ChatGroq)\n",
    "    answer = generate_answer(user_query, retrieved_titles, tab_data)\n",
    "\n",
    "    print(f\"\\nðŸ§  Answer:\\n{answer.content}\")\n",
    "\n",
    "\n",
    "# question 1 :- Want to know about the academic appeals.\n",
    "# question 2 :- How to File A Complaint for civil rights.\n",
    "# question 3 :- Can you tell me the capital of france?\n",
    "# question 4 :- Want to understand about the Resources for students and families, high school educators and college access counselors, and college officials\n",
    "\n",
    "search_and_generate(\"Want to understand about the Resources for students and families, high school educators and college access counselors, and college officials\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
