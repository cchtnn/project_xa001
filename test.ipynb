{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "def get_data_from_website(url):\n",
    "    # Get response from the server\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 500:\n",
    "        print(\"Server error\")\n",
    "        return\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Step 1: Find all tab titles\n",
    "    tab_titles = soup.find_all(\"div\", class_=\"elementor-tab-title\")\n",
    "\n",
    "    # Step 2: Find all corresponding tab contents\n",
    "    tab_data = {}\n",
    "\n",
    "    for title_div in tab_titles:\n",
    "        tab_id = title_div.get(\"data-tab\")\n",
    "        tab_title = title_div.get_text(strip=True)\n",
    "\n",
    "        matching_content = soup.find(\"div\", class_=\"elementor-tab-content\", attrs={\"data-tab\": tab_id})\n",
    "        tab_content = matching_content.get_text(separator=\"\\n\", strip=True) if matching_content else \"\"\n",
    "\n",
    "        tab_data[tab_title] = tab_content\n",
    "\n",
    "    # ✅ Create 'data' folder if it doesn't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    # ✅ Save as JSON file\n",
    "    with open(\"data/tab_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tab_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"Data saved to data/tab_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/tab_data.json\n"
     ]
    }
   ],
   "source": [
    "get_data_from_website(\"https://www.dinecollege.edu/academics/academic-policies/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "with open('data/tab_data.json', 'r', encoding='utf-8') as f:\n",
    "    tab_data = json.load(f)\n",
    "\n",
    "# Combine tab title and content into a document\n",
    "documents = [f\"{key}: {value}\" for key, value in tab_data.items()]\n",
    "metadata = list(tab_data.keys())\n",
    "\n",
    "# Load a pre-trained embedding model from Hugging Face\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "embeddings = model.encode(documents, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# Create FAISS index\n",
    "embedding_dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # Using L2 similarity\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the index\n",
    "faiss.write_index(index, 'data/faiss_index.idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index and metadata saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the metadata for reverse lookup\n",
    "with open('data/faiss_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ FAISS index and metadata saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Top 2 Results for: 'Want to know about the academic appeals.'\n",
      "\n",
      "1. Title: Grades\n",
      "   Score: 0.9125\n",
      "   Content:\n",
      "General Grade Appeal\n",
      "Grades are determined solely by the individual faculty who taught the course for the session(s) or the semester(s). A student who wishes to contest a grade must first attempt to resolve the matter with the course faculty.\n",
      "If the matter cannot be resolved with the instructor, the...\n",
      "\n",
      "2. Title: Academics\n",
      "   Score: 1.0904\n",
      "   Content:\n",
      "Academic Appeals\n",
      "Students placed on academic probation or suspension may appeal to the Academic Standards Committee by filing an appeal form with the Office of the Registrar. The student has the right to appeal any action affecting their academic status by obtaining the appropriate form from the Off...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the saved FAISS index and metadata\n",
    "index = faiss.read_index('data/faiss_index.idx')\n",
    "with open('data/faiss_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Also load the tab_data to fetch full content for results\n",
    "with open('data/tab_data.json', 'r', encoding='utf-8') as f:\n",
    "    tab_data = json.load(f)\n",
    "\n",
    "def search_query(user_query, top_k=2):\n",
    "    # Convert query to embedding\n",
    "    query_vector = model.encode([user_query], convert_to_numpy=True)\n",
    "\n",
    "    # Perform similarity search\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "\n",
    "    # Print top-k matches\n",
    "    print(f\"\\n🔍 Top {top_k} Results for: '{user_query}'\\n\")\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        title = metadata[idx]\n",
    "        content = tab_data[title]\n",
    "        score = distances[0][i]\n",
    "        print(f\"{i+1}. Title: {title}\")\n",
    "        print(f\"   Score: {score:.4f}\")\n",
    "        print(f\"   Content:\\n{content[:300]}{'...' if len(content) > 300 else ''}\\n\")\n",
    "\n",
    "# Example\n",
    "search_query(\"Want to know about the academic appeals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "        model=\"Llama3-8b-8192\",\n",
    "        temperature=0,\n",
    "        max_tokens=4192,\n",
    "        timeout=30,\n",
    "        max_retries=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(user_query, retrieved_titles, tab_data):\n",
    "    # Combine relevant tab content\n",
    "    retrieved_docs = \"\\n\\n\".join([f\"{title}: {tab_data[title]}\" for title in retrieved_titles if title in tab_data])\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following information, answer the question.\n",
    "\n",
    "    Information:\n",
    "    {retrieved_docs}\n",
    "\n",
    "    Question: {user_query}\n",
    "\n",
    "    Answer in a clear, helpful, and concise manner.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using ChatGroq (LLaMA3)\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_generate(user_query, top_k=3):\n",
    "    query_vector = model.encode([user_query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "\n",
    "    retrieved_titles = [metadata[idx] for idx in indices[0]]\n",
    "\n",
    "    # Generate the answer using LLaMA (ChatGroq)\n",
    "    answer = generate_answer(user_query, retrieved_titles, tab_data)\n",
    "\n",
    "    print(f\"\\n🧠 Answer:\\n{answer.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Answer:\n",
      "According to the provided information, the academic appeals process at Diné College is as follows:\n",
      "\n",
      "* If a student wishes to contest a grade, they must first attempt to resolve the matter with the course faculty.\n",
      "* If the matter cannot be resolved with the instructor, the student may appeal to the appropriate Dean of School. The student must provide evidence as to why the grade posted by the faculty is an error.\n",
      "* If the matter is not resolved with the Dean of School, the student may appeal a final time to the Academic Standards Committee.\n",
      "* The decision of the Academic Standards Committee is final.\n",
      "\n",
      "Additionally, students placed on academic probation or suspension may appeal to the Academic Standards Committee by filing an appeal form with the Office of the Registrar.\n",
      "\n",
      "It's also important to note that students have the right to appeal any action affecting their academic status by obtaining the appropriate form from the Office of the Registrar: Appeal of Suspension, Appeal of Probation, Grade Appeal, or General Appeal.\n",
      "\n",
      "If you have any further questions or concerns, please feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "search_and_generate(\"Want to know about the academic appeals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
